{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5cf1dd",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b6050949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "corpus = [\n",
    "    'the sun is a star',\n",
    "    'the moon is a satellite',\n",
    "    'the sun and moon are celestial bodies'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0975839",
   "metadata": {},
   "source": [
    "### vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5b9dd150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sun', 'is', 'star', 'celestial', 'and', 'bodies', 'are', 'the', 'moon', 'satellite']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def tokenize(sentence) :\n",
    "    return re.findall(r'\\b\\w+\\b', sentence)\n",
    "\n",
    "vocabulary = set()\n",
    "\n",
    "for doc in corpus :\n",
    "    tokens = tokenize(doc)\n",
    "    for word in tokens :\n",
    "        if len(word) > 1 :\n",
    "            vocabulary.add(word.lower())\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "print(vocabulary)\n",
    "print(len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f160bfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 0, 'are': 1, 'bodies': 2, 'celestial': 3, 'is': 4, 'moon': 5, 'satellite': 6, 'star': 7, 'sun': 8, 'the': 9}\n",
      "['and', 'are', 'bodies', 'celestial', 'is', 'moon', 'satellite', 'star', 'sun', 'the']\n"
     ]
    }
   ],
   "source": [
    "vocabulary.sort()\n",
    "word2index = {}\n",
    "for i in range(len(vocabulary)) :\n",
    "    word2index[vocabulary[i]] = i\n",
    "print(word2index)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74418d13",
   "metadata": {},
   "source": [
    "## TF-IDF calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a83ad1",
   "metadata": {},
   "source": [
    "### term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bf19081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n",
      "Term Frequency Matrix:\n",
      "[[0. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "tf = np.zeros((len(corpus), len(vocabulary)))\n",
    "print(tf.shape)\n",
    "\n",
    "for i in range(len(corpus)) :\n",
    "    tokens = tokenize(corpus[i])\n",
    "    for j in range(len(tokens)) :\n",
    "        if tokens[j].lower() in word2index :\n",
    "            tf[i][word2index[tokens[j].lower()]] += 1    # raw count\n",
    "\n",
    "print(\"Term Frequency Matrix:\")\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def2e3b",
   "metadata": {},
   "source": [
    "### inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2a1293d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF values:\n",
      "[1.69314718 1.69314718 1.69314718 1.69314718 1.28768207 1.28768207\n",
      " 1.69314718 1.69314718 1.28768207 1.        ]\n"
     ]
    }
   ],
   "source": [
    "idf = np.zeros(len(vocabulary))\n",
    "for i in range(len(vocabulary)) :\n",
    "    count = 0\n",
    "    for doc in corpus :\n",
    "        tokens = [token.lower() for token in tokenize(doc)]\n",
    "        if vocabulary[i] in tokens :\n",
    "            count += 1\n",
    "    idf[i] = np.log((len(corpus) +1)/ (count + 1)) + 1         # using smoothing by adding +1\n",
    "\n",
    "print(\"IDF values:\")\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c572db7e",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f38a81da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix:\n",
      "[[0.         0.         0.         0.         0.4804584  0.\n",
      "  0.         0.63174505 0.4804584  0.37311881]\n",
      " [0.         0.         0.         0.         0.4804584  0.4804584\n",
      "  0.63174505 0.         0.         0.37311881]\n",
      " [0.4261835  0.4261835  0.4261835  0.4261835  0.         0.32412354\n",
      "  0.         0.         0.32412354 0.25171084]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "tf_idf = tf * idf.reshape(1, -1)     # multiplying the tf and idf values\n",
    "tf_idf = normalize(tf_idf, 'l2', axis = 1)    # using l2 normalisation\n",
    "\n",
    "print(\"TF-IDF matrix:\")\n",
    "print(tf_idf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f122d",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0af7b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary from CountVectorizer:\n",
      "{'the': 9, 'sun': 8, 'is': 4, 'star': 7, 'moon': 5, 'satellite': 6, 'and': 0, 'are': 1, 'celestial': 3, 'bodies': 2}\n",
      "features from CountVectorizer:\n",
      "['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "CountVectorizer values:\n",
      "[[0 0 0 0 1 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = CountVectorizer()\n",
    "X1 = vect1.fit_transform(corpus)\n",
    "\n",
    "print(\"Vocabulary from CountVectorizer:\")\n",
    "print(vect1.vocabulary_)\n",
    "\n",
    "print(\"features from CountVectorizer:\")\n",
    "print(vect1.get_feature_names_out())\n",
    "\n",
    "print(\"CountVectorizer values:\")\n",
    "print(X1.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aca4bb",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a41fc0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary from TfidfVectorizer:\n",
      "{'the': 9, 'sun': 8, 'is': 4, 'star': 7, 'moon': 5, 'satellite': 6, 'and': 0, 'are': 1, 'celestial': 3, 'bodies': 2}\n",
      "features from TfidfVectorizer:\n",
      "['and' 'are' 'bodies' 'celestial' 'is' 'moon' 'satellite' 'star' 'sun'\n",
      " 'the']\n",
      "TfidfVectorizer:\n",
      "[[0.         0.         0.         0.         0.4804584  0.\n",
      "  0.         0.63174505 0.4804584  0.37311881]\n",
      " [0.         0.         0.         0.         0.4804584  0.4804584\n",
      "  0.63174505 0.         0.         0.37311881]\n",
      " [0.4261835  0.4261835  0.4261835  0.4261835  0.         0.32412354\n",
      "  0.         0.         0.32412354 0.25171084]]\n"
     ]
    }
   ],
   "source": [
    "vect2 = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "X2 = vect2.fit_transform(corpus)\n",
    "\n",
    "print(\"Vocabulary from TfidfVectorizer:\")\n",
    "print(vect2.vocabulary_)\n",
    "\n",
    "print(\"features from TfidfVectorizer:\")\n",
    "print(vect2.get_feature_names_out())\n",
    "\n",
    "print(\"TfidfVectorizer:\")\n",
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff62b7e3",
   "metadata": {},
   "source": [
    "### TF and CountVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f28a545c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF values calculate :\n",
      "[[0. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 0. 0. 1. 1.]]\n",
      "Count Vectoriser values :\n",
      "[[0 0 0 0 1 0 0 1 1 1]\n",
      " [0 0 0 0 1 1 1 0 0 1]\n",
      " [1 1 1 1 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF values calculate :\")\n",
    "print(tf)\n",
    "print(\"Count Vectoriser values :\")\n",
    "print(X1.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca6908",
   "metadata": {},
   "source": [
    "### TF-IDF and Tfidfvectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "507dd564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF values calculated :\n",
      "[[0.         0.         0.         0.         0.4804584  0.\n",
      "  0.         0.63174505 0.4804584  0.37311881]\n",
      " [0.         0.         0.         0.         0.4804584  0.4804584\n",
      "  0.63174505 0.         0.         0.37311881]\n",
      " [0.4261835  0.4261835  0.4261835  0.4261835  0.         0.32412354\n",
      "  0.         0.         0.32412354 0.25171084]]\n",
      "TfidfVectorizer values :\n",
      "[[0.         0.         0.         0.         0.4804584  0.\n",
      "  0.         0.63174505 0.4804584  0.37311881]\n",
      " [0.         0.         0.         0.         0.4804584  0.4804584\n",
      "  0.63174505 0.         0.         0.37311881]\n",
      " [0.4261835  0.4261835  0.4261835  0.4261835  0.         0.32412354\n",
      "  0.         0.         0.32412354 0.25171084]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF values calculated :\")\n",
    "print(tf_idf)\n",
    "print(\"TfidfVectorizer values :\")\n",
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566eb158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
